{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb19430c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This model aims to provide accurate results for prediction on survivors with the titanic dataset on kaggle\n",
    "Currently holds an accuracy of 78% with test data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#        Importing pandas to explore dataset\n",
    "import pandas as pd\n",
    "\n",
    "#        Loading dataset\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Loading test data for later use\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "X_test = test_data[[ \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]]\n",
    "\n",
    "#        Showing dataset head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f0c707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob\\AppData\\Local\\Temp/ipykernel_12036/770576051.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Sex'] = pd.get_dummies(test_data['Sex'])\n",
      "C:\\Users\\Rob\\AppData\\Local\\Temp/ipykernel_12036/770576051.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Embarked'] = pd.get_dummies(test_data['Embarked'])\n"
     ]
    }
   ],
   "source": [
    "#        Showing data set columns\n",
    "data.columns\n",
    "#        Showing empty values within columns\n",
    "#        Found 177 ages, 687 Cabin and 2 Embarked values missing\n",
    "data.isna().sum()\n",
    "\n",
    "#getting dummies for Sex,Embarked and make them readable for the classifiers\n",
    "data['Sex'] = pd.get_dummies(data['Sex'])\n",
    "data['Embarked'] = pd.get_dummies(data['Embarked'])\n",
    "\n",
    "#same for test_data\n",
    "X_test['Sex'] = pd.get_dummies(test_data['Sex'])\n",
    "X_test['Embarked'] = pd.get_dummies(test_data['Embarked'])\n",
    "\n",
    "#setting cols that we can use vs ones we can't use\n",
    "num_cols = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Sex\",\"Embarked\"]\n",
    "cat_cols = [\"Ticket\", \"Cabin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57e057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning data to X,y\n",
    "X = data[[ \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]]\n",
    "y = data[\"Survived\"]\n",
    "\n",
    "#transforming data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "X  = imp.fit_transform(X[num_cols])\n",
    "\n",
    "#X_test too\n",
    "X_test = imp.fit_transform(X_test[num_cols])\n",
    "\n",
    "\n",
    "#Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size= 0.8, test_size=0.2, \n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3acefa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean squared error, the metric we're using to calculate error on the classifiers\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ffdbb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000) MSE: 0.18994413407821228\n",
      "KNeighborsClassifier() MSE: 0.2681564245810056\n",
      "GaussianNB() MSE: 0.2122905027932961\n",
      "[14:32:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=7, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=45, n_jobs=12,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) MSE: 0.12290502793296089\n",
      "SVC(probability=True) MSE: 0.27932960893854747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob\\anaconda3\\envs\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=11, random_state=0) MSE: 0.13966480446927373\n"
     ]
    }
   ],
   "source": [
    "#importing classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#this function fits each one of the classifiers we're using, in order to get its MAE, the lower, the better. \n",
    "def get_results():\n",
    "    lr_def  = LogisticRegression(max_iter=1000)\n",
    "    knn_def = KNeighborsClassifier()\n",
    "    clf_def = GaussianNB()\n",
    "    xgb_def = xgb.XGBClassifier(n_estimators=45,max_depth=7,random_state=0,tree_method=\"exact\")\n",
    "    svc_def = SVC(probability=True)\n",
    "    rfc_def = RandomForestClassifier(max_depth=11, random_state=0)\n",
    "    \n",
    "    classifiers = [lr_def,knn_def, clf_def, xgb_def, svc_def, rfc_def]\n",
    "    for i in classifiers:\n",
    "        i.fit(X_train,y_train)\n",
    "        i.preds = i.predict(X_valid)\n",
    "        i.MSE = mean_squared_error(y_valid, i.preds)\n",
    "        print(str(i) + \" MSE\"+ \": \" + str(i.MSE))\n",
    "        \n",
    "get_results()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12a693d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:21:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob\\anaconda3\\envs\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#From this output we can conclude that the best model to use is XGBClassifier\n",
    "#So we're gonna fit it with the full data. \n",
    "\n",
    "xgb_final = xgb.XGBClassifier(max_depth=7,random_state=0)\n",
    "xgb_final.fit(X,y)\n",
    "xgb_final_preds = xgb_final.predict(X_test)\n",
    "\n",
    "\n",
    "#To use only when decided on an algorithm to use, then submit preds to kaggle. \n",
    "final_data = {'PassengerId': test_data[\"PassengerId\"], 'Survived': xgb_final_preds}\n",
    "final_data = pd.DataFrame(data=final_data)\n",
    "final_data.to_csv('name_submission.csv', index=False)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "That should do it for now, this model grants you a place within top 15% on kaggle titanic competition. \n",
    "To improve  model accuracy, we have to work on the data that was left out. Name, Ticket and Cabin were left out. \n",
    "Next task is to make this data useful. \n",
    "More to come. \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
